{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、数据生成器\n",
    "## 1、自建数据生成器\n",
    "自建数据生成器仅支持二分类，建议使用API数据生成器。对于二分类问题，将下面代码中的两个路径正则匹配好即可<br>\n",
    "```\n",
    "real_list  = glob.glob(r\".\\Hotdog\\train\\hotdog/*.png\")  \n",
    "glitch_list = glob.glob(r\".\\Hotdog\\train\\not-hotdog/*png\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# real_list  = glob.glob(r\".\\train\\1/*.png\")\n",
    "# glitch_list = glob.glob(r\".\\train\\0/*png\")\n",
    "\n",
    "real_list  = glob.glob(r\".\\Hotdog\\train\\hotdog/*.png\")  \n",
    "glitch_list = glob.glob(r\".\\Hotdog\\train\\not-hotdog/*png\")\n",
    "\n",
    "list_img = real_list+glitch_list\n",
    "\n",
    "print(len(real_list), len(glitch_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "\n",
    "def get_batch(img_list, label_list, batch_size=8, show=False):\n",
    "    # 在方法中需要用while写成死循环，因为每个step不会重新调用方法\n",
    "    while True:\n",
    "        index = np.random.choice(range(len(img_list)), batch_size)\n",
    "        batch_list = [img_list[i] for i in index]\n",
    "        batch_row = [cv2.imread(img) for img in batch_list]\n",
    "        batch_gray = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in batch_row]\n",
    "        batch_matrix = [cv2.resize(i,(224, 224),interpolation=cv2.INTER_CUBIC) for i in batch_gray]\n",
    "        batch_label = [label_list[i] for i in index]\n",
    "        if show:\n",
    "            pp.pprint(list(zip(batch_list, batch_label)))\n",
    "        batch_matrix = np.concatenate(np.expand_dims(batch_matrix, axis=0), axis=0).astype(float)\n",
    "        batch_label = np.array(batch_label)\n",
    "        # batch_matrix = np.expand_dims(batch_matrix, -1)\n",
    "        batch_matrix = (batch_matrix).astype(int)/255.\n",
    "        yield batch_matrix, batch_label  # , batch_list\n",
    "\n",
    "\n",
    "list_lab = np.zeros([len(list_img), 2], dtype=int)\n",
    "list_lab[:len(real_list), 0] = 1  # real: [1, 0]\n",
    "list_lab[len(real_list):, 1] = 1  # fake: [0, 1]\n",
    "b = next(get_batch(list_img, list_lab, show=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num = np.random.randint(0, len(b))\n",
    "img = (b[0][num]*255).astype(np.uint8) \n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "# print(b[2][num])\n",
    "# pp.pprint(list(zip(b[1][:], b[2][:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、API数据生成器\n",
    "官方的数据读取器，路径指定到图片父级目录，其下有各个class的子目录即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3850 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# train_datagen=ImageDataGenerator(rescale=1./255)\n",
    "# train_flow=train_pic_gen.flow_from_directory(r'./hotdog\\train',target_size=(128, 128),batch_size=32,class_mode='categorical')\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=False)\n",
    "\n",
    "train_flow = train_datagen.flow_from_directory(\n",
    "        r'.\\train',            # this is the target directory\n",
    "        target_size=(224, 224),  # all images will be resized to 150x150\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、网络定义\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 5, 5, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 2)                 13107970  \n",
      "=================================================================\n",
      "Total params: 34,910,754\n",
      "Trainable params: 13,107,970\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense,Flatten,Dropout,Input\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.applications import InceptionV3\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "TransforLearning = True\n",
    "model = Sequential()\n",
    "if not TransforLearning:\n",
    "    model.add(Conv2D(32, 3, 3, input_shape=(224, 224, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())# this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "else:\n",
    "    inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    model.add(inception)\n",
    "    # build a classifier model to put on top of the convolutional model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "    top_model.add(Dense(64, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "    # 数据集不够大，这里将inception部分参数冻结，不参与训练\n",
    "    model.add(top_model)\n",
    "    for layer in inception.layers[:]:\n",
    "        layer.trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 1048s 2s/step - loss: 0.6029 - acc: 0.6771\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 1057s 2s/step - loss: 0.5119 - acc: 0.7497\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 1074s 2s/step - loss: 0.4856 - acc: 0.7697\n"
     ]
    }
   ],
   "source": [
    "from keras import losses\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "samples_per_epoch = 10000  # len(list_img)\n",
    "batch_size = 32\n",
    "\n",
    "# K.set_value(sgd.lr, 0.5 * K.get_value(sgd.lr))\n",
    "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.compile(optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              loss='binary_crossentropy',  # 'categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit_generator(train_flow,  \n",
    "                    # get_batch(list_img, list_lab),\n",
    "                    steps_per_epoch=2*samples_per_epoch//batch_size, # samples_per_epoch//batch_size, \n",
    "                    epochs=3,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[TensorBoard(log_dir='./tmp/log', write_graph=True)])\n",
    "# model.fit(img, label, batch_size=8, epochs=10)\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、测试\n",
    "## 1、自建数据生成器\n",
    "如果上面用的get_batch函数获取的训练数据，则这里也要使用自建的数据获取流程<br>\n",
    "须将下面两个路径替换为测试图片的路径：\n",
    "```\n",
    "test_real_list  = glob.glob(\"./0/*.jpg\")\n",
    "test_glitch_list = glob.glob(\"./1/*jpg\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e8de7fa47ccc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest_real_list\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./test/0/*.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtest_glitch_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./test/1/*.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_list_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_real_list\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtest_glitch_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_real_list  = glob.glob(\"./test/0/*.png\")\n",
    "test_glitch_list = glob.glob(\"./test/1/*.png\")\n",
    "test_list_img = test_real_list + test_glitch_list\n",
    "\n",
    "img_test = [cv2.imread(i) for i in test_list_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4743ae847797>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m img_test = [cv2.resize(i,(224, 224),interpolation=cv2.INTER_CUBIC)\n\u001b[1;32m----> 2\u001b[1;33m             for i in img_test if not i==None]\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimg_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlabel_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_test' is not defined"
     ]
    }
   ],
   "source": [
    "img_test = [cv2.resize(i,(224, 224),interpolation=cv2.INTER_CUBIC)\n",
    "            for i in img_test if not i==None]\n",
    "img_test = np.concatenate(np.expand_dims(img_test, axis=0), axis=0)/255\n",
    "\n",
    "label_test = np.zeros([len(img_test), 2], dtype=int)\n",
    "label_test[:len(test_real_list), 0] = 1\n",
    "label_test[len(test_real_list):, 1] = 1\n",
    "# pp.pprint(list(zip(test_list_img, label_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、API数据生成器\n",
    "否则使用迭代器即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=False)\n",
    "\n",
    "test_flow = train_datagen.flow_from_directory(\n",
    "        r'.\\Hotdog\\test',            # this is the target directory\n",
    "        target_size=(224, 224),  # all images will be resized to 150x150\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 5, 5, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 2)                 13107970  \n",
      "=================================================================\n",
      "Total params: 34,910,754\n",
      "Trainable params: 13,107,970\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras.models as KM\n",
    "\n",
    "model = KM.load_model('model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('loss', 6.2614383697509766), ('acc', 0.46875)]\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "# result = model.evaluate(img_test, label_test)  # \n",
    "result = model.evaluate_generator(test_flow, 1)\n",
    "pp.pprint(list(zip(model.metrics_names, result)))\n",
    "# [('loss', 4.7238349914550781), ('acc', 0.59375)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
